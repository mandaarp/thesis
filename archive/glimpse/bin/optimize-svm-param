#!/usr/bin/python

# Copyright (c) 2011 Mick Thomure
# All rights reserved.
#
# Please see the file COPYING in this distribution for usage
# terms.

#
# This script searches for the optimal SVM margin penalty with respect to a given training set.
#

from glimpse import util
import numpy
import os
import random
import sys

import warnings
warnings.simplefilter("ignore", DeprecationWarning)

VERBOSE = False

def RunCommandAndCapture(cmd):
    if VERBOSE:
        print "CMD: %s" % cmd
    stdout, stdin, stderr = os.popen3(cmd, 'r')
    out, err = stdin.read().strip(), stderr.read().strip()
    return out, err

def ArgMax(values):
    return numpy.array(values).argmax()

class SvmRunner(object):
    def __init__(self, svm_train, svm_predict):
        self.svm_train = svm_train
        self.svm_predict = svm_predict
        self.tmp = util.TempDir()
    def _Train(self, train, c=None):
        model = self.tmp.MakePath('model')
        # Train SVM model
        cmd = self.svm_train + " -t 0 "
        if c != None:
            cmd += "-c %s " % c
        cmd += train + " " + model
        return RunCommandAndCapture(cmd)
    def _Test(self, test, results=None):
        model = self.tmp.MakePath('model')
        if results == None:
            results = self.tmp.MakePath('results')
        cmd = ' '.join([ self.svm_predict, test, model, results ])
        return RunCommandAndCapture(cmd)

class LibSvmRunner(SvmRunner):
    def __init__(self, biased, bin_dir=None, num_splits=5):
        if bin_dir == None:
          bin_dir = os.path.split(sys.argv[0])[0]
        svm_train = os.path.join(bin_dir, 'libsvm', 'svm-train')
        svm_predict = os.path.join(bin_dir, 'libsvm', 'svm-predict')
        if not biased:
            # Map bin name from "svm-train" to "svm-train-unbiased"
            svm_train += '-unbiased'
        SvmRunner.__init__(self, svm_train, svm_predict)
        self.num_splits = num_splits
    def Train(self, train, c=None):
        out, err = self._Train(train, c)
        if not outy.split('\n')[1].startswith('optimization finished'):
            raise Exception("Error while training SVM")
    def Test(self, test, results=None):
        out, err = self._Test(test, results)
        out = out.split(' ')
        if out[0] != 'Accuracy':
            raise Exception("Error while testing SVM")
        accuracy = out[2]
        if not accuracy.endswith('%'):
            raise Exception("Error while testing SVM")
        return float(accuracy[:-1]) / 100.0
    def Validate(self, train, c):
        out, err = RunCommandAndCapture("%s -t 0 -v %d -c %s %s" % (self.svm_train, self.num_splits, c, train))
        last_line = out.split('\n')[-1]
        if not last_line.startswith("Cross Validation Accuracy = "):
            raise Exception("Failed to cross-validate SVM: " + err)
        return float(last_line.split(' ')[-1][:-1]) / 100.0

def Concat(sublists):
    result = []
    for sublist in sublists:
        result.extend(sublist)
    return result

class SvmCrossValidator(object):
    def __init__(self, num_splits, num_repeats=1):
        self.num_splits = num_splits
        self.num_repeats = num_repeats
        self.tmp = util.TempDir()
    def _CrossValidateOnce(self, runner, insts, ssize, *params):
        # Randomize training set
        random.shuffle(insts)
        # Split in M segments
        segments = [ insts[x:x+ssize] for x in range(0, len(insts), ssize) ]
        sum_accuracy = 0
        train_fname = self.tmp.MakePath('train')
        test_fname = self.tmp.MakePath('test')
        # For each segment:
        for segment in range(self.num_splits):
            # Test on current segment after training on others
            util.WriteLines(Concat(segments[:segment] + segments[segment+1:]),
                            train_fname)
            util.WriteLines(segments[segment], test_fname)
            runner.Train(train_fname, *params)
            sum_accuracy += runner.Test(test_fname)
        return sum_accuracy / float(self.num_splits)
    def CrossValidate(self, runner, fname, *params):
        # Read training instances into memory
        insts = util.ReadLines(fname)
        assert(len(insts) % self.num_splits == 0)
        ssize = len(insts) / self.num_splits
        sum_accuracy = 0
        # Repeat N times
        for repeat in range(self.num_repeats):
            sum_accuracy += self._CrossValidateOnce(runner, insts, ssize, *params)
        # We're taking average accuracy across sets
        return sum_accuracy / float(self.num_repeats)

class SvmLightRunner(SvmRunner):
    def __init__(self, biased, bin_dir, num_splits=5):
        if not biased:
            raise Exception("Unbiased SVMLight run is not implemented yet")
        svm_train = os.path.join(bin_dir, 'svm_learn')
        svm_predict = os.path.join(bin_dir, 'svm_classify')
        SvmRunner.__init__(self, svm_train, svm_predict)
        self.cross_validator = SvmCrossValidator(num_splits)
    def Train(self, train, c=None):
        out, err = self._Train(train, c)
        if out.split('\n')[-1] != "Writing model file...done":
            raise Exception("Failed to train SVM on (%s): %s" % (train, err))
    def Test(self, test, results=None):
        out, err = self._Test(test, results)
        line = out.split('\n')[-2]
        if not line.startswith("Accuracy on test set:"):
            raise Exception("Failed to test SVM on (%s): %s" + (test, err))
        return float(line.split(' ')[4][:-1]) / 100.0
    def Validate(self, train, c):
        return self.cross_validator.CrossValidate(self, train, c)

class SvmRunnerWrapper(object):
    def __init__(self, runner, train):
        self.runner = runner
        self.train = train
        self.cache = {}
    def Validate(self, c):
        if c in self.cache:
            accuracy = self.cache[c]
        else:
            accuracy = self.runner.Validate(self.train, c)
            self.cache[c] = accuracy
        if VERBOSE:
            print "Validate(%s): %s" % (c, accuracy)
        return accuracy

def Search(runner, points=None, epsilon=0.001, last_c=-1, last_accuracy=-1, fixed_point_cnt=0):
    if points == None:
        #points = [ 10**x for x in range(-3,4) ]
        points = [ 2**x for x in range(-8,2) ]
    else:
        assert(len(points) > 1)
    if VERBOSE:
        print "Search:", points
    accuracies = map(runner.Validate, points)
    i = ArgMax(accuracies)
    # No change in best point, may have reached a fixed point or may
    # just need to look more near this point.
    if points[i] == last_c:
        fixed_point_cnt += 1
        # If we've drilled down near this point enough, just return.
        if fixed_point_cnt == 2:
            return points[i]
    else:
        fixed_point_cnt = 0
        # If the point has changed, but the accuracy hasn't increased
        # much, just return.
        if accuracies[i] - last_accuracy <= epsilon:
            return points[i]
    # Search around best point.
    next_points = [ points[i] ]
    if i == 0:
        next_points = [
            points[i],
            points[i] + abs(points[i+1] - points[i])/2.0,
            points[i+1],
        ]
    elif i == len(points)-1:
        next_points = [
            points[i-1],
            points[i] - abs(points[i] - points[i-1])/2.0,
            points[i],
        ]
    else:
        next_points = [
            points[i-1],
            points[i] - abs(points[i] - points[i-1])/2.0,
            points[i],
            points[i] + abs(points[i+1] - points[i])/2.0,
            points[i+1],
        ]
    return Search(runner,
                  next_points,
                  epsilon,
                  points[i],
                  accuracies[i],
                  fixed_point_cnt)

def main():
    global VERBOSE
    opts, args = util.GetOptions("b:p:s:uv")
    bin_dir = None
    biased = True
    num_splits = 5
    runner = LibSvmRunner
    for opt,arg in opts:
        if opt == '-b':
            bin_dir = arg
        if opt == '-p':
            if arg.lower() == "svmlight":
                runner = SvmLightRunner
            elif arg.lower() == "libsvm":
                runner = LibSvmRunner
            else:
                raise util.UsageException("Bad SVM package: %s" % arg)
        elif opt == '-s':
            num_splits = int(arg)
        elif opt == '-u':
            biased = False
        elif opt == '-v':
            VERBOSE = True
    if len(args) < 1:
        raise util.UsageException("Missing training file")
    train = args[0]
    if runner == SvmLightRunner and bin_dir == None:
        raise util.UsageException("Bin directory required when using SVMLight")
    runner = runner(biased, bin_dir, num_splits)
    runner = SvmRunnerWrapper(runner, train)
    c = Search(runner)
    if VERBOSE:
        print "Best parameter is C = %s with accuracy %s%%" % (c, runner.Validate(c)*100)
    else:
        print c

try:
    main()
except util.UsageException, e:
    if e.msg:
        print >>sys.stderr, e.msg
    util.Usage("[options] TRAIN.SVM\n" + \
        "    -b     Bin directory\n" + \
        "    -p     SVM package to use (default: LIBSVM)\n" + \
        "    -s     Number of splits for cross-validation (defualt: 5)\n" + \
        "    -u     Unbiased SVM\n" + \
        "    -v     Use verbose status updates"
    )
